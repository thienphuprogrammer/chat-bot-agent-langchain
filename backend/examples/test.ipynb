{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:39:43.645070700Z",
     "start_time": "2025-01-08T06:39:43.630406800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getenv(\"NVIDIA_API_KEY\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:39:43.726612300Z",
     "start_time": "2025-01-08T06:39:43.645070700Z"
    }
   },
   "id": "5bc19223f0afcac3",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "model = ChatNVIDIA(model=\"meta/llama-3.1-405b-instruct\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:39:43.727607200Z",
     "start_time": "2025-01-08T06:39:43.659914500Z"
    }
   },
   "id": "5b5c3de4353109e",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:39:43.728596300Z",
     "start_time": "2025-01-08T06:39:43.676074700Z"
    }
   },
   "id": "11d1ba58a52410b2",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = Chroma.from_documents(documents, NVIDIAEmbeddings(model_name=\"nvidia/llama-3.2-nv-embedqa-1b-v2\"))\n",
    "retriever = vector.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:39:45.832196700Z",
     "start_time": "2025-01-08T06:39:43.733596400Z"
    }
   },
   "id": "59604080c905adf2",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.tools import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:39:45.850789400Z",
     "start_time": "2025-01-08T06:39:45.838402Z"
    }
   },
   "id": "833dab739007b310",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:39:45.883487100Z",
     "start_time": "2025-01-08T06:39:45.847432600Z"
    }
   },
   "id": "df99f7ffd2e93e32",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:39:45.885522400Z",
     "start_time": "2025-01-08T06:39:45.861787200Z"
    }
   },
   "id": "9f0faf423ab2cd3",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react-chat\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d45dc84d0b40183b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "PromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react-chat', 'lc_hub_commit_hash': '3ecd5f710db438a9cf3773c57d6ac8951eefd2cd9a9b2a0026a65a0893b86a6e'}, template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nTOOLS:\\n------\\n\\nAssistant has access to the following tools:\\n\\n{tools}\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n{chat_history}\\n\\nNew input: {input}\\n{agent_scratchpad}')"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:40:03.595891Z",
     "start_time": "2025-01-08T06:40:03.523900300Z"
    }
   },
   "id": "c2355ca3a1aeef20",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(model, tools, prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:40:10.680032900Z",
     "start_time": "2025-01-08T06:40:10.659470600Z"
    }
   },
   "id": "31e03b779fde9555",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "TOOLS:\n",
      "------\n",
      "\n",
      "Assistant has access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "Final Answer: [your response here]\n",
      "```\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous conversation history:\n",
      "{chat_history}\n",
      "\n",
      "New input: {input}\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.steps[1].template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:47:32.096531700Z",
     "start_time": "2025-01-08T06:47:32.011662700Z"
    }
   },
   "id": "17736f4ec6b2c11e",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to PromptTemplate is missing variables {'tools', 'tool_names'}.  Expected: ['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'] Received: ['input', 'intermediate_steps', 'chat_history', 'agent_scratchpad']\\nNote: if you intended {tools} to be part of the string and not a variable, please escape it with double curly braces like: '{{tools}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWho is Japan\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43ms prime minister?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mintermediate_steps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mchat_history\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\chatbot-agent-langchain-MeslnlcA\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3024\u001B[0m, in \u001B[0;36mRunnableSequence.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m   3022\u001B[0m             \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(step\u001B[38;5;241m.\u001B[39minvoke, \u001B[38;5;28minput\u001B[39m, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   3023\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3024\u001B[0m             \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3025\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[0;32m   3026\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\.virtualenvs\\chatbot-agent-langchain-MeslnlcA\\Lib\\site-packages\\langchain_core\\prompts\\base.py:208\u001B[0m, in \u001B[0;36mBasePromptTemplate.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags:\n\u001B[0;32m    207\u001B[0m     config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags\n\u001B[1;32m--> 208\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    209\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_format_prompt_with_error_handling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    211\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrun_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprompt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    213\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserialized\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_serialized\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\chatbot-agent-langchain-MeslnlcA\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1927\u001B[0m, in \u001B[0;36mRunnable._call_with_config\u001B[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001B[0m\n\u001B[0;32m   1923\u001B[0m     context \u001B[38;5;241m=\u001B[39m copy_context()\n\u001B[0;32m   1924\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, child_config)\n\u001B[0;32m   1925\u001B[0m     output \u001B[38;5;241m=\u001B[39m cast(\n\u001B[0;32m   1926\u001B[0m         Output,\n\u001B[1;32m-> 1927\u001B[0m         \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1928\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m   1929\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m   1930\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m   1931\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1932\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1933\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1934\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m   1935\u001B[0m     )\n\u001B[0;32m   1936\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1937\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[1;32m~\\.virtualenvs\\chatbot-agent-langchain-MeslnlcA\\Lib\\site-packages\\langchain_core\\runnables\\config.py:396\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[1;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    394\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[0;32m    395\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[1;32m--> 396\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\chatbot-agent-langchain-MeslnlcA\\Lib\\site-packages\\langchain_core\\prompts\\base.py:182\u001B[0m, in \u001B[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001B[1;34m(self, inner_input)\u001B[0m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_format_prompt_with_error_handling\u001B[39m(\u001B[38;5;28mself\u001B[39m, inner_input: \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PromptValue:\n\u001B[1;32m--> 182\u001B[0m     _inner_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43minner_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_prompt(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_inner_input)\n",
      "File \u001B[1;32m~\\.virtualenvs\\chatbot-agent-langchain-MeslnlcA\\Lib\\site-packages\\langchain_core\\prompts\\base.py:176\u001B[0m, in \u001B[0;36mBasePromptTemplate._validate_input\u001B[1;34m(self, inner_input)\u001B[0m\n\u001B[0;32m    170\u001B[0m     example_key \u001B[38;5;241m=\u001B[39m missing\u001B[38;5;241m.\u001B[39mpop()\n\u001B[0;32m    171\u001B[0m     msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    172\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mNote: if you intended \u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mexample_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;124m to be part of the string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    173\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m and not a variable, please escape it with double curly braces like: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    174\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mexample_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    175\u001B[0m     )\n\u001B[1;32m--> 176\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\n\u001B[0;32m    177\u001B[0m         create_message(message\u001B[38;5;241m=\u001B[39mmsg, error_code\u001B[38;5;241m=\u001B[39mErrorCode\u001B[38;5;241m.\u001B[39mINVALID_PROMPT_INPUT)\n\u001B[0;32m    178\u001B[0m     )\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m inner_input\n",
      "\u001B[1;31mKeyError\u001B[0m: \"Input to PromptTemplate is missing variables {'tools', 'tool_names'}.  Expected: ['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'] Received: ['input', 'intermediate_steps', 'chat_history', 'agent_scratchpad']\\nNote: if you intended {tools} to be part of the string and not a variable, please escape it with double curly braces like: '{{tools}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    {\n",
    "        \"input\": \"Who is Japan's prime minister?\",\n",
    "        \"intermediate_steps\": [],\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T06:47:39.956374100Z",
     "start_time": "2025-01-08T06:47:39.853205900Z"
    }
   },
   "id": "cd1d0cdae3ccd60c",
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
