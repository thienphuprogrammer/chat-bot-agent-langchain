{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T09:32:00.154056Z",
     "start_time": "2025-01-09T09:32:00.150087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.tracers.langchain import wait_for_all_tracers\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "\n",
    "from backend.src.common.constants import PERSONAL_CHAT_PROMPT_REACT\n",
    "from backend.src.core.chains import BaseChain\n",
    "from backend.src.core.indexing.multi_presentation_indexing import MultiPresentationIndexing\n",
    "from backend.src.core.models import ModelTypes\n",
    "from backend.src.core.processor.pdf_processor import PDFProcessor\n",
    "from backend.src.core.relevance.fusion import FusionRelevance\n",
    "from backend.src.core.retrieval import PDFRetrieval\n",
    "from backend.src.core.utils.prompt import *\n",
    "\n",
    "load_dotenv()\n"
   ],
   "id": "39f13a094f5655d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T09:32:00.202967Z",
     "start_time": "2025-01-09T09:32:00.199724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PDFQAChain(BaseChain):\n",
    "    def __init__(\n",
    "            self,\n",
    "            pdf_retriever: PDFRetrieval,\n",
    "            partial_variables: dict = None,\n",
    "            prompt_react_template: str = PERSONAL_CHAT_PROMPT_REACT,\n",
    "            multi_prompt_template: str = FUSION_PROMPT,\n",
    "            final_rag_prompt: str = FINAL_RAG_PROMPT,\n",
    "            model_kwargs=None,\n",
    "            config=None,\n",
    "            model_name: Optional[ModelTypes] = None,\n",
    "            base_model=None,\n",
    "            embeddings=None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            config=config,\n",
    "            model_name=model_name,\n",
    "            model_kwargs=model_kwargs,\n",
    "            base_model=base_model\n",
    "        )\n",
    "        self._embedder = embeddings\n",
    "        self._pdf_retriever = pdf_retriever\n",
    "        self._vector_store_manager = self._pdf_retriever.vector_store_manager\n",
    "        self._retriever = self._vector_store_manager.get_retriever()\n",
    "        self._multi_prompt_template = self._init_prompt_template(multi_prompt_template)\n",
    "        self._final_rag_prompt = self._init_prompt_template(final_rag_prompt)\n",
    "        self._pdf_retriever = PDFRetrieval(embedder=self._embedder, model=self._base_model)\n",
    "        if partial_variables is None:\n",
    "            partial_variables = {}\n",
    "        self._react_prompt = self._init_prompt_template_hub(template_path=prompt_react_template,\n",
    "                                                            partial_variables=partial_variables)\n",
    "\n",
    "        self._init_generate_chain(self._multi_prompt_template)\n",
    "        self._init_retrieval_chain(FusionRelevance.reciprocal_rank_fusion)\n",
    "        self._init_final_rag_chain(self._final_rag_prompt)\n",
    "\n",
    "    def _predict(self, message: str, conversation_id: str = \"\"):\n",
    "        try:\n",
    "            output = self.final_chain.invoke({\"question\": message})\n",
    "            return output\n",
    "        finally:\n",
    "            wait_for_all_tracers()\n",
    "\n",
    "    def __call__(self, message: str, conversation_id: str = \"\"):\n",
    "        output = self._predict(message, conversation_id)\n",
    "        return output\n"
   ],
   "id": "be3d9eedddc0ba18",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:12:25.196078Z",
     "start_time": "2025-01-09T10:12:25.143956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Khởi tạo các dependencies\n",
    "embedder = OllamaEmbeddings(model=\"llama3.2:1b\")\n",
    "model = ChatOllama(model=\"llama3.2:1b\")\n",
    "prompt_template = \"\"\"\n",
    "    You are an agent specializing in content summarization. Based on the provided context, provide the title of the document.\n",
    "\n",
    "    Context:\n",
    "    ----------\n",
    "    {context}\n",
    "    ----------\n",
    "    Keep your answer as concise as possible, limited to one or two sentences. Just answer what the title is, nothing else\n",
    "    This ensures clarity, brevity, and professionalism in the response.\n",
    "    \"\"\"\n",
    "prompt: ChatPromptTemplate = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "init_prompt_template = [\n",
    "    \"The title of the document\",\n",
    "]"
   ],
   "id": "9bdfc834896eda25",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T09:56:25.648662Z",
     "start_time": "2025-01-09T09:56:24.627962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "init_prompt = [Document(page_content=doc) for doc in init_prompt_template]\n",
    "\n",
    "# Khởi tạo PDFRetriever\n",
    "model_summary = MultiPresentationIndexing(model=model)\n",
    "pdf_processor = PDFProcessor()\n",
    "\n",
    "_, docs_summary = pdf_processor.process_pdf(pdf_path=\"../../../data/pdf/OmniPred.pdf\", summary_model=model_summary)\n",
    "pdf_summary_retriever = PDFRetrieval(embedder=embedder, model=model)\n",
    "pdf_summary_retriever.store(docs_summary)"
   ],
   "id": "825b49092ca70832",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:12:41.387764Z",
     "start_time": "2025-01-09T10:12:41.360344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = [j for i in init_prompt_template for j in pdf_summary_retriever.retriever(search_kwargs={\"k\": 4}).invoke(i)]\n",
    "result = '\\n'.join([doc.page_content for doc in result])\n",
    "\n",
    "print(result)"
   ],
   "id": "ec9254ed4b08cd42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document discusses OmniPred, a language model that can perform well against various gold-standard baselines. Specifically, it:\n",
      "\n",
      "- Performs competitively on tasks using its single-task variant (i.e., not finetuning)\n",
      "- Can adapt to new data through fine-tuning while still leveraging existing knowledge\n",
      "- Offers a potential expansion in the field of experimental design.\n",
      "The document appears to be a list of research papers related to large language models and their applications in various fields. Here's a summary of each paper:\n",
      "\n",
      "1. **OmniPred: Language Models as Universal Regressors** (2022)\n",
      "   - This paper proposes using large language models to encode clinical knowledge, making them universal regressors.\n",
      "   - The authors argue that traditional knowledge representation methods are not effective for capturing complex relationships between concepts.\n",
      "\n",
      "2. **Open source vizier: Distributed infrastructure and API for reliable and flexible blackbox optimization** (2022)\n",
      "   - This paper introduces Open Source Vizier, a distributed infrastructure and API for reliable and flexible black-box optimization of machine learning models.\n",
      "   - The authors demonstrate the ability to perform Bayesian optimization using this framework.\n",
      "\n",
      "3. **The vizier gaussian process bandit algorithm** (2024)\n",
      "   - This paper presents the vizier Gaussian Process Bandit Algorithm, which is a novel approach to online learning with uncertainty.\n",
      "   - The algorithm combines Bayesian inference and bandits to improve efficiency and accuracy in machine learning models.\n",
      "\n",
      "4. **Design-bench: Benchmarks for data-driven offline model-based optimization** (2022)\n",
      "   - This paper highlights Design-Bench as a benchmark dataset for evaluating the performance of data-driven offline model-based optimization methods.\n",
      "   - The authors demonstrate that their approach can significantly outperform traditional optimization methods.\n",
      "\n",
      "5. **From words to numbers: Your large language model is secretly A capable regressor when given in-context examples** (2024)\n",
      "   - This paper showcases a surprising property of large language models, which can perform regression tasks with high accuracy using only context.\n",
      "   - The authors demonstrate that their approach has applications in areas such as natural language processing and data analysis.\n",
      "\n",
      "6. **Few-shot Bayesian optimization with deep kernel surrogates** (2021)\n",
      "   - This paper explores the use of few-shot learning to optimize machine learning models using Bayesian optimization with deep kernel surrogates.\n",
      "   - The authors demonstrate the effectiveness of this approach for tasks such as hyperparameter tuning and model selection.\n",
      "\n",
      "7. **A new family of power transformations to improve normality or symmetry** (2000)\n",
      "   - This paper introduces a new class of power transformations that can be used to improve normality or symmetry in data.\n",
      "   - The authors demonstrate the effectiveness of these transformations for modeling real-world data.\n",
      "\n",
      "8. **Surrogate NAS benchmarks: Going beyond the limited search spaces of tabular NAS benchmarks** (2022)\n",
      "   - This paper highlights the limitations of traditional benchmarking approaches for large neural network architectures and proposes new surrogate benchmarks to overcome them.\n",
      "   - The authors demonstrate that their approach can significantly improve the efficiency and effectiveness of these benchmarks.\n",
      "\n",
      "9. **Unlocking the transferability of tokens in deep models for tabular data** (2023)\n",
      "   - This paper explores the use of transferable knowledge in machine learning models to improve performance on tabular datasets.\n",
      "   - The authors demonstrate the effectiveness of this approach using a pre-trained language model as a feature extractor.\n",
      "\n",
      "10. **Fine-tuning language models from human preferences** (2019)\n",
      "    - This paper proposes fine-tuning large language models for specific tasks, such as sentiment analysis or question answering.\n",
      "    - The authors demonstrate that their approach can improve the performance of these models using human-preferred features.\n",
      "The document discusses the OmniPred project, which aims to develop a deep learning model that can simultaneously regress on multiple tasks or objectives across different input spaces and scales. Here's a summary of the main points:\n",
      "\n",
      "1. The authors trained a BBOB (Binary Binary Objective) model using a multi-task approach, where they regressed on 4D Bayesian optimization boundary problems (BBOB functions) with different objective scales.\n",
      "2. The authors also explored the benefits of text-based transfer learning and whether online finetuning can improve accuracy over unseen studies outside the pretraining set.\n",
      "3. They tested two models: StepEllipsoidal-4D, which shifts the input space by various amounts, and Weierstrass-4D, which has a different objective scale.\n",
      "4. The authors found that both models achieved high accuracy across different tasks and scales, with the StepEllipsoidal-4D model performing better in some cases.\n",
      "\n",
      "Some specific findings include:\n",
      "\n",
      "* The authors showed that the multi-task approach can be used to train deep learning models on complex problems like BBOB functions with varying objective scales.\n",
      "* They also demonstrated the effectiveness of online finetuning and text-based transfer learning, which they believe can improve accuracy over unseen studies outside the pretraining set.\n",
      "\n",
      "The authors suggest that their work has implications for various fields, including machine learning, computer vision, and natural language processing.\n",
      "The document appears to be a research paper or study on OmniPred, which is a language model developed by Google for predictive regression tasks. Here's a summary of the main points:\n",
      "\n",
      "**Data Preprocessing**\n",
      "\n",
      "* The raw data from studies can be chaotic due to user evaluations and other issues.\n",
      "* Preprocessing techniques are applied to clean and filter out problematic trials, such as ignoring or failing to evaluate proposed inputs (x) or encountering infeasible values for y objectives.\n",
      "\n",
      "**Filtering Studies by User**\n",
      "\n",
      "* A hard limit of 103 trials per study is used to prevent dominated data distributions from emerging.\n",
      "* Automated users (e.g. power users involved in unit tests) are filtered out to prevent them from dominating the dataset.\n",
      "* Specific studies from these users are disregarded for finetuning experiments with unseen studies.\n",
      "\n",
      "**Real-World Data Descriptions**\n",
      "\n",
      "* No filters were applied to the entire database.\n",
      "* Experiments using the \"Bid Simulation\" feature involve proprietary data, and public code is available on GitHub (https://github.com/google/init2winit).\n",
      "\n",
      "**AutoML and Vertex AI Components**\n",
      "\n",
      "* The document mentions various components, including:\n",
      "\t+ AutoML: a collection of proprietary tools for automating model optimization.\n",
      "\t+ Vertex AI: a platform for automated ML model selection and training in tabular or text data.\n",
      "\t+ Protein Design: involves 50+ parameters to represent categorical protein building blocks.\n",
      "\t+ Vertex AI (Tabular and Text): trains models for tabular or text data, including classification, information extraction, and sentiment analysis.\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:12:58.509934Z",
     "start_time": "2025-01-09T10:12:58.428033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = [j for i in init_prompt_template for j in pdf_summary_retriever.retriever(search_kwargs={\"k\": 4}).invoke(i)]\n",
    "result = '\\n'.join([doc.page_content for doc in result])\n",
    "\n",
    "chain = prompt | model\n",
    "print(chain.invoke(result).content)"
   ],
   "id": "3982a8263767d551",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OmniPred: Language Models as Universal Regressors\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:14:59.019573Z",
     "start_time": "2025-01-09T10:14:58.911632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def retrieve_and_process_docs(init_prompt_template):\n",
    "    # Retrieve documents for each query in init_prompt_template\n",
    "    result = [\n",
    "        j\n",
    "        for i in init_prompt_template\n",
    "        for j in pdf_summary_retriever.retriever(search_kwargs={\"k\": 4}).invoke(i)\n",
    "    ]\n",
    "    # Join the page_content of all documents into a single string\n",
    "    return '\\n'.join([doc.page_content for doc in result])\n",
    "\n",
    "\n",
    "# Step 2: Create a Runnable for the retrieval and processing logic\n",
    "retrieve_chain = RunnableLambda(retrieve_and_process_docs)\n",
    "\n",
    "# Step 3: Define the final chain\n",
    "chain = retrieve_chain | prompt | model\n",
    "\n",
    "# Step 4: Run the final chain\n",
    "print(chain.invoke(init_prompt_template).content)"
   ],
   "id": "de41f7e7f17de41a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OmniPred: Language Models as Universal Regressors\n"
     ]
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# print(docs_summary)\n",
    "# print(pdf_summary_retriever.retriever().invoke(\"Main ideas of the document\"))\n",
    "# chain = (\n",
    "#         {\n",
    "#             \"context\": pdf_summary_retriever.retriever().map()\n",
    "#                        | (lambda x: \"\\n\".join([doc.page_content for doc in x]))\n",
    "#         }\n",
    "#         | prompt\n",
    "#         | model\n",
    "# )\n",
    "# print(chain.invoke(init_prompt))\n",
    "\n",
    "# docs = pdf_processor.process_pdf(pdf_path=\"../../../data/pdf/OmniPred.pdf\")\n",
    "# pdf_retriever = PDFRetrieval(embedder=embedder, model=model)\n",
    "# pdf_retriever.store(docs)\n",
    "\n",
    "# Khởi tạo QA chains\n",
    "# pdf_qa_chain = PDFQAChain(pdf_retriever=pdf_retriever, base_model=model)\n",
    "\n",
    "# Chạy QA chains\n",
    "\n",
    "# result = pdf_qa_chain(query)\n",
    "# print(result)\n"
   ],
   "id": "4a40420bba4b024c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
